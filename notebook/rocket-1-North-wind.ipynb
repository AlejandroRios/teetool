{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/anaconda3/envs/teetool/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import teetool as tt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_trajectories = \"rocket-A-Northern-45deg.csv\"\n",
    "#file_trajectories = \"rocket-A-Northern-10deg.csv\"\n",
    "file_pickle = \"rocket-north.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFile(fileName):\n",
    "    \"\"\"\n",
    "    downloads file if not yet done so\n",
    "    \"\"\"\n",
    "    \n",
    "    locale_path = \"data/{0}\".format(fileName)\n",
    "    online_path = \"https://www.southampton.ac.uk/~wje1n13/camrocsim/{0}\".format(fileName)\n",
    "    \n",
    "    if not os.path.isfile(locale_path):\n",
    "        !wget $online_path -O $locale_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getFile(file_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "M = 200 # resampling (reduces points, doesn't interpolate), negative turns off\n",
    "store_this_case_x = \"t2 [-]\" # choose dimension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "df = pd.read_csv(\"data/{0}\".format(file_trajectories))\n",
    "\n",
    "# rename columns\n",
    "df.rename(columns={'TIME_SECONDS_DOUBLE': 't [s]', \n",
    "                   'EASTINGS_METERS_DOUBLE': 'x [m]',\n",
    "                   'NORTHINGS_METERS_DOUBLE': 'y [m]',\n",
    "                   'ALTITUDE_METERS_DOUBLE': 'z [m]',\n",
    "                   'DISTANCE_METERS_DOUBLE': 'd [m]'}, inplace=True)\n",
    "\n",
    "\n",
    "# \"is_event column\n",
    "temp = np.diff(df[\"EVENT_INT\"])\n",
    "temp = np.concatenate(([0],temp))\n",
    "df[\"is_event\"] = (temp == 1)\n",
    "\n",
    "df_us = df # copy\n",
    "\n",
    "# normalise x y z GLOBALLY (all trajectories)\n",
    "these_cells_input = [\"x [m]\", \"y [m]\", \"z [m]\"]\n",
    "these_cells_output = [\"x [-]\", \"y [-]\", \"z [-]\"]\n",
    "\n",
    "for (i, cell_input) in enumerate(these_cells_input):\n",
    "    cell_output = these_cells_output[i]\n",
    "    df_us.loc[:,cell_output] = (df_us[cell_input] - df_us[cell_input].min()) / ( df_us[cell_input].max() - df_us[cell_input].min() )\n",
    "\n",
    "# normalise time / distance LOCALLY (per trajectory)\n",
    "these_cells_input = [\"t [s]\", \"d [m]\"]\n",
    "these_cells_output = [\"t [-]\", \"d [-]\"]\n",
    "\n",
    "for (i, cell_input) in enumerate(these_cells_input):\n",
    "    cell_output = these_cells_output[i]\n",
    "    df_col = df_us[cell_input]\n",
    "    temp = [];\n",
    "    for i1 in df_us.ID_STR.unique():\n",
    "        # this trajectory\n",
    "        df1 = df_col[(df_us[\"ID_STR\"] == i1)]\n",
    "        temp1 = ( df1 - df1.min() ) / ( df1.max() - df1.min() )\n",
    "        # concatenate\n",
    "        temp = np.concatenate((temp, temp1.values), axis=0)\n",
    "    # store altered dimension\n",
    "    df_us[cell_output] = temp\n",
    "    \n",
    "# find partitions\n",
    "df_part = pd.DataFrame(columns = [\"EVENT_INT\",\"ID_STAGE_STR\",\"DIM\",\"MIN\",\"MAX\"])\n",
    "\n",
    "these_dim = [\"t [-]\", \"d [-]\"]\n",
    "\n",
    "# use mean trajectory as guide\n",
    "df1 = df_us[df_us[\"ID_STR\"] == 0]\n",
    "\n",
    "last_max_dic = {}\n",
    "\n",
    "for this_dim in these_dim:\n",
    "    last_max_dic[this_dim] = 0\n",
    "    \n",
    "\n",
    "for this_stage in df_us[\"ID_STAGE_STR\"].unique():\n",
    "    # this stage\n",
    "\n",
    "    for this_event in df_us[\"EVENT_INT\"].unique():\n",
    "        # this event\n",
    "\n",
    "        # consider only this segment of events\n",
    "        df2 = df_us[df_us[\"EVENT_INT\"] == this_event]\n",
    "\n",
    "        for this_dim in these_dim:\n",
    "            # this dimension\n",
    "\n",
    "            # extract this dimension\n",
    "            df3 = df2[this_dim]\n",
    "\n",
    "            # extract minimum range of this segment\n",
    "            event_min = last_max_dic[this_dim]\n",
    "\n",
    "            # extract maximum range of this segment\n",
    "            event_max = df3.max()\n",
    "            \n",
    "            # update last max\n",
    "            last_max_dic[this_dim] = event_max\n",
    "\n",
    "            # calculate different\n",
    "            #event_diff = event_max - event_min\n",
    "\n",
    "            # new addition\n",
    "            df_temp = pd.DataFrame({\"EVENT_INT\":[this_event],\n",
    "                                    \"DIM\":[this_dim],\"MIN\":[event_min],\n",
    "                                    \"MAX\":[event_max],\n",
    "                                   \"ID_STAGE_STR\":[this_stage]})\n",
    "\n",
    "            # append addition\n",
    "            df_part = df_part.append(df_temp,ignore_index=True)\n",
    "\n",
    "# normalise time / distance SUPER LOCALLY (per trajectory, per segment)\n",
    "these_cells_input = [\"t [-]\", \"d [-]\"]\n",
    "these_cells_output = [\"t2 [-]\", \"d2 [-]\"]\n",
    "\n",
    "for (i, this_dim) in enumerate(these_cells_input):\n",
    "    \n",
    "    # input / output combination\n",
    "    cell_output = these_cells_output[i]\n",
    "    \n",
    "    # consider this dimension\n",
    "    #this_dim = df_us[cell_input]\n",
    "    \n",
    "    for this_traj in df_us.ID_STR.unique():\n",
    "        # this trajectory\n",
    "        #df2 = df1[(df_us[\"ID_STR\"] == this_traj)]\n",
    "        \n",
    "        for this_event in df_us.EVENT_INT.unique():\n",
    "            # single segment/event\n",
    "            these_rows = ((df_us[\"ID_STR\"] == this_traj) &\n",
    "                            (df_us[\"EVENT_INT\"] == this_event))\n",
    "            \n",
    "            # extract data\n",
    "            temp_data = df_us.loc[these_rows, this_dim]\n",
    "                        \n",
    "            # normalised array (one trajectory, one segment)\n",
    "            temp_norm = ( temp_data - temp_data.min() ) / ( temp_data.max() - temp_data.min() )\n",
    "            \n",
    "            # extract information \n",
    "            these_rows2 = ((df_part[\"DIM\"] == this_dim) &\n",
    "                               (df_part[\"EVENT_INT\"] == this_event))\n",
    "            \n",
    "            event_min = df_part.loc[these_rows2, \"MIN\"].values\n",
    "            event_max = df_part.loc[these_rows2, \"MAX\"].values\n",
    "            \n",
    "            # modify to fit stretch\n",
    "            temp_fit = (event_max - event_min) * temp_norm + event_min\n",
    "            \n",
    "            # store new data in cell_output\n",
    "            df_us.loc[these_rows, cell_output] = temp_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flick data into arrays\n",
    "\n",
    "# number of trajectories\n",
    "N = df_us.ID_STR.unique().size\n",
    "\n",
    "cluster_data = []\n",
    "\n",
    "for (n, id_str) in enumerate(df_us.ID_STR.unique()):\n",
    "    \n",
    "    df1 = df_us[df_us[\"ID_STR\"] == id_str]\n",
    "    \n",
    "    Yn = np.array([df1[\"x [m]\"].values, df1[\"y [m]\"].values, df1[\"z [m]\"].values]).transpose()\n",
    "    # yn = np.reshape(Yn, (-1,1), order='F')\n",
    "    xn = np.array(df1[store_this_case_x].values)\n",
    "    \n",
    "    # filter finite values\n",
    "    mask = np.isfinite(xn)\n",
    "    Yn = Yn[mask, :]\n",
    "    xn = xn[mask]\n",
    "    \n",
    "    # add tuple to list\n",
    "    cluster_data.append((xn, Yn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temporary store data in pickle\n",
    "pd.to_pickle(cluster_data, file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** overview [Cambridge Rocketry Simulator] ***\n",
      "0 [rocket trajectories] [-] [-]\n",
      "*** overview [Cambridge Rocketry Simulator] ***\n",
      "0 [rocket trajectories] [*] [-]\n",
      "number of calculations: 3375\n",
      "........\n",
      "*** overview [Cambridge Rocketry Simulator] ***\n",
      "0 [rocket trajectories] [*] [*]\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "#settings = {\"model_type\":\"EM\", \"ngaus\":100, \"basis_type\":\"bernstein\", \"nbasis\":5}\n",
    "settings = {\"model_type\":\"resampling\", \"ngaus\":300}\n",
    "\n",
    "# build world\n",
    "world_name = \"Cambridge Rocketry Simulator\"\n",
    "\n",
    "# build world\n",
    "new_world = tt.World(name=world_name, ndim=3)\n",
    "\n",
    "# modify default resolution\n",
    "new_world.setResolution(xstep=15, ystep=15, zstep=15)\n",
    "\n",
    "new_world.addCluster(cluster_data, \"rocket trajectories\")\n",
    "\n",
    "# overview\n",
    "new_world.overview()\n",
    "\n",
    "# model\n",
    "new_world.buildModel(0, settings)\n",
    "new_world.overview()  # overview\n",
    "\n",
    "# alter extension\n",
    "new_world.fraction_to_expand = 0.5\n",
    "\n",
    "# log\n",
    "new_world.buildLogProbality(0)\n",
    "new_world.overview()  # overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visuals by mayavi\n",
    "visual = tt.visual_3d.Visual_3d(new_world)\n",
    "# visualise trajectories\n",
    "visual.plotTrajectories([0])\n",
    "# visualise intersection\n",
    "visual.plotLogProbability([0], pmin=0.0, pmax=0.1)\n",
    "# visualise outline\n",
    "visual.plotOutline()\n",
    "# wait to close\n",
    "visual.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
